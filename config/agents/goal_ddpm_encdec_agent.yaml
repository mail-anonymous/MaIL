_target_: agents.oc_ddpm_goal_agent.DiffusionAgent
_recursive_: false

action_seq_size: ${inference_action_seq}
obs_seq_len: ${obs_seq}

model:
  _target_: agents.oc_ddpm_goal_agent.DiffusionPolicy
  _recursive_: false

  visual_input: True
  device: ${device}

  model:
    _target_: agents.models.oc_ddpm.diffusion_policy.Diffusion
    _recursive_: false

    state_dim: 256 #${obs_dim}
    action_dim: ${action_dim}
    beta_schedule: 'cosine'
    n_timesteps: ${diff_steps}
    loss_type: 'l2'
    clip_denoised: true
    predict_epsilon: true
    device: ${device}
    diffusion_x: False
    diffusion_x_M: 10

    model:
      _target_: agents.models.goal_ddpm.oc_ddpm.DiffusionEncDec
      _recursive_: false
      state_dim: 256 #${obs_dim}
      action_dim: ${action_dim}
      goal_conditioned: False
      goal_seq_len: 10
      obs_seq_len: ${obs_seq}
      action_seq_len: ${train_action_seq}
      embed_pdrob: 0
      # Architecture details
      embed_dim: 128 #${n_embd}
      device: ${device}
      linear_output: true

      encoder:
        _target_: agents.models.goal_ddpm.oc_ddpm.TransformerEncoder
        embed_dim: 128 #${n_embd}
        n_heads: 4
        n_layers: ${encoder_n_layer}
        attn_pdrop: 0.1
        resid_pdrop: 0.1
        bias: False
        block_size: ${add:${window_size}, 5}

      decoder:
        _target_: agents.models.goal_ddpm.oc_ddpm.TransformerDecoder
        embed_dim: 128 #${n_embd}
        cross_embed: 128 #${n_embd} # allow cross embedding to have different dimension
        n_heads: 4
        n_layers: ${decoder_n_layer}
        attn_pdrop: 0.1
        resid_pdrop: 0.1
        bias: False
        block_size: ${add:${window_size}, 5}

  obs_encoder:
    _target_: agents.module.vision.multi_image_obs_encoder.MultiImageObsEncoder
    shape_meta:
      # acceptable types: rgb, low_dim
      obs:
        agentview_rgb:
          shape: [3, 128, 128]
          type: rgb
        eye_in_hand_rgb:
          shape: [3, 128, 128]
          type: rgb
    #        robot_ee_pos:
    #          shape: [3]
    #          type default: low_dim
    #      robot0_eef_quat:
    #        shape: [4]
    #      robot0_gripper_qpos:
    #        shape: [2]
    #    action:
    #      shape: [10]

    rgb_model:
      _target_: agents.module.vision.get_model.get_resnet
      input_shape: [3, 128, 128]
      output_size: 128
    resize_shape: null
    #    crop_shape: [ 84, 84 ]
    # constant center crop
    random_crop: False
    use_group_norm: True
    share_rgb_model: False
    imagenet_norm: True

#  goal_encoder:
#    _target_: agents.module.vision.multi_image_obs_encoder.MultiImageObsEncoder
#    shape_meta:
#      # acceptable types: rgb, low_dim
#      obs:
#        goal_rgb:
#          shape: [ 3, 128, 128 ]
#          type: rgb
#
#    rgb_model:
#      _target_: agents.module.vision.get_model.get_resnet
#      input_shape: [ 3, 128, 128 ]
#      output_size: 256
#    resize_shape: null
#    #    crop_shape: [ 84, 84 ]
#    # constant center crop
#    random_crop: False
#    use_group_norm: True
#    share_rgb_model: False
#    imagenet_norm: True

optimization:
  _target_: torch.optim.Adam
  lr: 5e-4 # for transformer
#  lr: 5e-4 # for MLP
  weight_decay: 0

#optimization:
#  _target_: torch.optim.AdamW
#  lr: 1.0e-4
#  betas: [0.9, 0.995]
#  eps: 1.0e-8
#  weight_decay: 0.1

trainset: ${trainset}
valset: ${valset}
train_batch_size: ${train_batch_size}
val_batch_size: ${val_batch_size}
num_workers: ${num_workers}
epoch: ${epoch}
device: ${device}
scale_data: ${scale_data}
eval_every_n_epochs: ${eval_every_n_epochs}

discount: 0.99
use_ema: True
decay: 0.995
update_ema_every_n_steps: 1
goal_window_size: 1
window_size: ${window_size}
diffusion_kde: false
diffusion_kde_samples: 100
goal_conditioned: False